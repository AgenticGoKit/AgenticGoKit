package main

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/kunalkushwaha/agenticgokit/core/vnext"
	_ "github.com/kunalkushwaha/agenticgokit/plugins/llm/ollama"
	_ "github.com/kunalkushwaha/agenticgokit/plugins/memory/memory" // Register memory provider
)

func main() {
	fmt.Println("ü§ñ Personal Assistant with Memory (Conversation History)")
	fmt.Println("=========================================================\n")

	ctx := context.Background()

	// Step 1: Create agent with memory integration enabled
	// The agent will automatically manage conversation history
	agent, err := vnext.NewBuilder("personal-assistant").
		WithConfig(&vnext.Config{
			Name: "personal-assistant",
			SystemPrompt: `You are a helpful personal assistant. 
Remember information from our conversation and provide personalized responses.`,
			LLM: vnext.LLMConfig{
				Provider:    "ollama",
				Model:       "gemma3:1b",
				Temperature: 0.7,
				MaxTokens:   80, // Short responses for faster demo
			},
			Memory: &vnext.MemoryConfig{
				Provider: "memory", // Use "memory" provider (registered by plugin)
				RAG: &vnext.RAGConfig{
					MaxTokens:       500,
					PersonalWeight:  0.6,
					KnowledgeWeight: 0.4,
					HistoryLimit:    10,
				},
			},
			Timeout: 90 * time.Second, // Generous timeout for Ollama
		}).
		Build()

	if err != nil {
		log.Fatalf("Failed to create agent: %v", err)
	}

	// Step 2: Initialize agent
	if err := agent.Initialize(ctx); err != nil {
		log.Fatalf("Failed to initialize agent: %v", err)
	}
	defer agent.Cleanup(ctx)

	// Step 3: Demo conversations showing memory working
	conversations := []struct {
		input string
		note  string // what this conversation demonstrates
	}{
		{
			input: "My name is Kunal and I'm a Go developer.",
			note:  "Storing user information in memory",
		},
		{
			input: "I work on microservices using Docker and Kubernetes.",
			note:  "Adding more context to memory",
		},
		{
			input: "What is my name?",
			note:  "Testing memory recall - should remember 'Kunal'",
		},
		{
			input: "What kind of developer am I?",
			note:  "Should recall Go developer",
		},
		{
			input: "What tools do I use?",
			note:  "Should remember Docker and Kubernetes",
		},
	}

	fmt.Println("üí¨ Demonstration: Memory-Powered Personalized Responses\n")
	fmt.Println("======================================================================")
	fmt.Println()

	for i, conv := range conversations {
		fmt.Printf("üë§ User [%d]: %s\n", i+1, conv.input)
		fmt.Printf("   üí° %s\n\n", conv.note)

		result, err := agent.Run(ctx, conv.input)
		if err != nil {
			log.Printf("‚ùå Error: %v\n\n", err)
			continue
		}

		fmt.Printf("ü§ñ Assistant: %s\n", result.Content)

		// Show memory usage
		if result.MemoryUsed {
			fmt.Printf("   ÔøΩ Memory: Used (queries=%d)\n", result.MemoryQueries)
		} else {
			fmt.Printf("   ‚ö†Ô∏è  Memory: Not used\n")
		}

		fmt.Printf("   ‚è±Ô∏è  Duration: %v\n", result.Duration)
		fmt.Println()
		fmt.Println("----------------------------------------------------------------------")
		fmt.Println()

		// Small delay between requests
		time.Sleep(500 * time.Millisecond)
	}

	fmt.Println("======================================================================")
	fmt.Println("‚úÖ Demo Complete!")
	fmt.Println("\nüìä Key Features Demonstrated:")
	fmt.Println("   ‚úÖ Memory persistence (user profile & preferences)")
	fmt.Println("   ‚úÖ Context-aware responses (RAG retrieves relevant context)")
	fmt.Println("   ‚úÖ Personalization (responses tailored to user)")
	fmt.Println("   ‚úÖ Memory integration with LLM (enriched prompts)")
	fmt.Println("\nüí° Try modifying the stored preferences and see how responses change!")
}
