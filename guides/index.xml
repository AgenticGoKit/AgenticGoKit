<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>guides :: AgenticGoKit Docs</title>
    <link>http://localhost:1313/AgenticGoKitDocs/guides/index.html</link>
    <description>How-To Guides Navigation: Documentation Home → Guides&#xA;Task-oriented guides for specific development scenarios and common tasks.&#xA;Quick Navigation Setup &amp; Configuration LLM Providers - Configure different LLM providers Vector Databases - Set up vector storage for RAG MCP Tools - Integrate Model Context Protocol tools Development Testing Agents - Test multi-agent systems Debugging - Debug agent interactions Best Practices - Development best practices Web Search Integration - Add web search capabilities to agents Research Assistant - Build multi-agent research systems Visualization - Generate workflow diagrams with Mermaid Framework &amp; Tools Framework Comparison - Compare AgenticGoKit with other frameworks Troubleshooting - Common issues and solutions Deployment &amp; Operations Production Deployment - Deploy and scale your agents Guide Structure Each guide follows this format:</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/AgenticGoKitDocs/guides/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>guides</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/readme/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/readme/index.html</guid>
      <description>How-To Guides Navigation: Documentation Home → Guides&#xA;Task-oriented guides for specific development scenarios and common tasks.&#xA;Quick Navigation Setup &amp; Configuration LLM Providers - Configure different LLM providers Vector Databases - Set up vector storage for RAG MCP Tools - Integrate Model Context Protocol tools Development Testing Agents - Test multi-agent systems Debugging - Debug agent interactions Best Practices - Development best practices Web Search Integration - Add web search capabilities to agents Research Assistant - Build multi-agent research systems Visualization - Generate workflow diagrams with Mermaid Framework &amp; Tools Framework Comparison - Compare AgenticGoKit with other frameworks Troubleshooting - Common issues and solutions Deployment &amp; Operations Production Deployment - Deploy and scale your agents Guide Structure Each guide follows this format:</description>
    </item>
    <item>
      <title>AgentBasics</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/agentbasics/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/agentbasics/index.html</guid>
      <description>Agent Basics Understanding the AgenticGoKit Agent System&#xA;This guide covers the fundamental concepts of building agents in AgenticGoKit, from the basic interfaces to advanced multi-agent orchestration patterns.&#xA;Core Concepts AgentHandler Interface The AgentHandler is the primary interface for implementing agent logic in AgenticGoKit:&#xA;type AgentHandler interface { Run(ctx context.Context, event Event, state State) (AgentResult, error) }&#xD;Key Components:&#xA;Event: Contains the user input and metadata State: Thread-safe storage for agent data AgentResult: The agent’s response and updated state Multi-Agent Orchestration AgenticGoKit supports multiple orchestration patterns for coordinating agents:</description>
    </item>
    <item>
      <title>Examples</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/examples/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/examples/index.html</guid>
      <description>AgenticGoKit Examples This guide provides practical examples of building AI agents and workflows with AgenticGoKit, from simple single-agent applications to complex multi-agent orchestrations.&#xA;Table of Contents Quick Start Examples Single Agent Examples Multi-Agent Workflows Tool Integration Examples Production Examples Custom Provider Examples Quick Start Examples Simple Query Agent (5 minutes) The fastest way to create an agent that can answer questions:&#xA;package main import ( &#34;context&#34; &#34;fmt&#34; &#34;log&#34; &#34;github.com/kunalkushwaha/agenticgokit/core&#34; ) func main() { // Initialize MCP for tool discovery core.QuickStartMCP() // Create LLM provider (using mock for this example) llm := &amp;core.MockLLM{} // Create an agent agent, err := core.NewMCPAgent(&#34;helper&#34;, llm) if err != nil { log.Fatal(err) } // Create state with query state := core.NewState() state.Set(&#34;query&#34;, &#34;What is the capital of France?&#34;) // Run agent result, err := agent.Run(context.Background(), state) if err != nil { log.Fatal(err) } fmt.Println(&#34;Response:&#34;, result.GetResult()) }&#xD;Multi-Agent Orchestration (Quick Start) Generate complete multi-agent workflows with the CLI:</description>
    </item>
    <item>
      <title>Configuration</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/configuration/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/configuration/index.html</guid>
      <description>Configuration Management Managing AgentFlow Configuration with agentflow.toml&#xA;AgentFlow uses TOML configuration files to manage all aspects of your agent system: LLM providers, MCP servers, multi-agent orchestration settings, workflow visualization, and more.&#xA;Basic Configuration Structure agentflow.toml Template # Project metadata name = &#34;My Agent System&#34; version = &#34;1.0.0&#34; description = &#34;AgentFlow-powered agent workflow&#34; # Logging configuration log_level = &#34;info&#34; # debug, info, warn, error # Multi-Agent Orchestration Configuration [orchestration] mode = &#34;sequential&#34; # sequential, collaborative, loop, mixed, route timeout_seconds = 30 # Timeout for orchestration operations max_iterations = 5 # Maximum iterations for loop mode # Sequential mode: agents process in order sequential_agents = [&#34;agent1&#34;, &#34;agent2&#34;, &#34;agent3&#34;] # Collaborative mode: agents process in parallel collaborative_agents = [&#34;analyzer&#34;, &#34;validator&#34;, &#34;processor&#34;] # Loop mode: single agent repeats loop_agent = &#34;processor&#34; # Mixed mode: combine collaborative and sequential # collaborative_agents = [&#34;analyzer&#34;, &#34;validator&#34;] # sequential_agents = [&#34;processor&#34;, &#34;reporter&#34;] # Workflow Visualization [visualization] enabled = true output_dir = &#34;./docs/diagrams&#34; diagram_type = &#34;flowchart&#34; # flowchart, sequence, etc. direction = &#34;TD&#34; # TD, LR, BT, RL show_metadata = true show_agent_types = true # LLM Provider configuration [provider] type = &#34;azure&#34; # azure, openai, ollama, mock api_key = &#34;${AZURE_OPENAI_API_KEY}&#34; endpoint = &#34;https://your-resource.openai.azure.com&#34; deployment = &#34;gpt-4&#34; api_version = &#34;2024-02-15-preview&#34; model = &#34;gpt-4&#34; max_tokens = 2000 temperature = 0.7 timeout = &#34;30s&#34; # MCP (Model Context Protocol) configuration [mcp] enabled = true cache_enabled = true cache_ttl = &#34;5m&#34; connection_timeout = &#34;30s&#34; max_retries = 3 # MCP server definitions [mcp.servers.search] command = &#34;npx&#34; args = [&#34;-y&#34;, &#34;@modelcontextprotocol/server-web-search&#34;] transport = &#34;stdio&#34; [mcp.servers.docker] command = &#34;npx&#34; args = [&#34;-y&#34;, &#34;@modelcontextprotocol/server-docker&#34;] transport = &#34;stdio&#34; # Error handling and routing [error_routing] validation_errors = &#34;error_handler&#34; timeout_errors = &#34;timeout_handler&#34; critical_errors = &#34;critical_handler&#34; default_error_handler = &#34;error_handler&#34; # Optional: Metrics and monitoring [metrics] enabled = false prometheus_port = 8090&#xD;Provider Configuration Azure OpenAI [provider] type = &#34;azure&#34; api_key = &#34;${AZURE_OPENAI_API_KEY}&#34; endpoint = &#34;${AZURE_OPENAI_ENDPOINT}&#34; deployment = &#34;${AZURE_OPENAI_DEPLOYMENT}&#34; api_version = &#34;2024-02-15-preview&#34; model = &#34;gpt-4&#34; max_tokens = 2000 temperature = 0.7 timeout = &#34;30s&#34; max_retries = 3&#xD;Required Environment Variables:</description>
    </item>
    <item>
      <title>CustomTools</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/customtools/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/customtools/index.html</guid>
      <description>Custom Tools Guide This guide covers building custom tools for AgentFlow agents. Learn how to create AgentFlow-native tools using the FunctionTool interface and how to integrate external MCP servers for extended functionality.&#xA;🎯 Overview AgentFlow supports two types of custom tools:&#xA;AgentFlow-Native Tools: Built using the FunctionTool interface and registered with the tool registry External MCP Tools: Tools from external MCP servers that are discovered and integrated automatically Key Benefits:</description>
    </item>
    <item>
      <title>Providers</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/providers/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/providers/index.html</guid>
      <description>LLM Providers Multi-Provider LLM Integration in AgentFlow&#xA;AgentFlow provides a unified interface for working with different LLM providers. This guide covers configuration, usage patterns, and provider-specific features.&#xA;Provider Overview AgentFlow supports multiple LLM providers through a unified ModelProvider interface:&#xA;Azure OpenAI (Default) - Enterprise-ready with robust scaling OpenAI - Direct API access to GPT models Ollama - Local models for privacy and cost control Mock - Testing and development ModelProvider Interface All providers implement the same interface:</description>
    </item>
    <item>
      <title>MemoryProviderSetup</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/memoryprovidersetup/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/memoryprovidersetup/index.html</guid>
      <description>Memory Provider Setup Guide Complete setup guides for AgenticGoKit memory providers&#xA;AgenticGoKit supports multiple memory providers for different use cases. This guide provides step-by-step setup instructions for each provider, from development to production deployment.&#xA;📚 Table of Contents Overview In-Memory Provider PostgreSQL + pgvector Setup Weaviate Setup Provider Comparison Migration Guide Troubleshooting 🎯 Overview Provider Selection Guide Provider Best For Persistence Scalability Setup Complexity memory Development, Testing ❌ No ⚠️ Single instance ✅ Minimal pgvector Production, Enterprise ✅ Yes ✅ High ⚠️ Moderate weaviate Large-scale Vector Ops ✅ Yes ✅ Very High ⚠️ Moderate Quick Start Recommendations Just getting started? → Use memory provider Building a production app? → Use pgvector provider Need advanced vector features? → Use weaviate provider 💾 In-Memory Provider Perfect for development, testing, and temporary sessions</description>
    </item>
    <item>
      <title>MemoryTroubleshooting</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/memorytroubleshooting/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/memorytroubleshooting/index.html</guid>
      <description>Memory System Troubleshooting Guide This guide helps you troubleshoot common issues with the AgentFlow memory system, especially when using the scaffold-generated projects.&#xA;Quick Diagnosis Use the memory debug command to quickly diagnose issues:&#xA;# Basic overview and connection test agentcli memory # Detailed configuration validation agentcli memory --validate # Show current configuration agentcli memory --config&#xD;Common Issues and Solutions 1. Dimension Mismatch Errors Error Message:&#xA;❌ Configuration Error: nomic-embed-text requires 768 dimensions, but 1536 configured&#xD;💡 Solution: Update agentflow.toml [agent_memory] dimensions = 768&#xD;Cause: The embedding model dimensions don’t match the configured dimensions in your agentflow.toml.</description>
    </item>
    <item>
      <title>EmbeddingModelGuide</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/embeddingmodelguide/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/embeddingmodelguide/index.html</guid>
      <description>Embedding Model Intelligence Guide AgentFlow includes an intelligent embedding model system that automatically configures appropriate settings based on your embedding model choice. This guide explains how to use and benefit from this system.&#xA;Overview The Embedding Model Intelligence system:&#xA;Automatically configures dimensions based on your chosen embedding model Validates compatibility between embedding models and memory providers Provides recommendations for optimal model selection Offers troubleshooting guidance for common issues Supported Models Ollama Models (Recommended for Local Development) nomic-embed-text:latest ⭐ Recommended Dimensions: 768 Provider: ollama Notes: Excellent general-purpose embedding model with good performance Best for: Local development, privacy-focused applications # Install and use ollama pull nomic-embed-text:latest agentcli create myproject --memory-enabled --embedding-provider ollama --embedding-model nomic-embed-text:latest&#xD;mxbai-embed-large Dimensions: 1024 Provider: ollama Notes: Larger model with better quality, requires more resources Best for: Applications requiring higher embedding quality ollama pull mxbai-embed-large agentcli create myproject --memory-enabled --embedding-provider ollama --embedding-model mxbai-embed-large&#xD;all-minilm Dimensions: 384 Provider: ollama Notes: Lightweight and fast, good for development Best for: Resource-constrained environments, rapid prototyping ollama pull all-minilm agentcli create myproject --memory-enabled --embedding-provider ollama --embedding-model all-minilm&#xD;OpenAI Models (Production Ready) text-embedding-3-small ⭐ Recommended Dimensions: 1536 Provider: openai Notes: Cost-effective OpenAI embedding model with good performance Best for: Production applications with budget considerations export OPENAI_API_KEY=&#34;your-api-key&#34; agentcli create myproject --memory-enabled --embedding-provider openai --embedding-model text-embedding-3-small&#xD;text-embedding-3-large Dimensions: 3072 Provider: openai Notes: Highest quality OpenAI embedding model, more expensive Best for: Applications requiring maximum embedding quality agentcli create myproject --memory-enabled --embedding-provider openai --embedding-model text-embedding-3-large&#xD;text-embedding-ada-002 (Legacy) Dimensions: 1536 Provider: openai Notes: Legacy OpenAI model, use text-embedding-3-small instead Status: Not recommended for new projects Testing Models dummy Dimensions: 1536 Provider: dummy Notes: Simple embeddings for testing only, not suitable for production Best for: Testing, development without external dependencies Automatic Configuration When you create a project, the system automatically:</description>
    </item>
    <item>
      <title>RAGConfiguration</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/ragconfiguration/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/ragconfiguration/index.html</guid>
      <description>RAG Configuration Guide Configuring Retrieval-Augmented Generation in AgentFlow&#xA;AgentFlow provides comprehensive RAG (Retrieval-Augmented Generation) capabilities through flexible TOML configuration. This guide covers all configuration options for building knowledge-aware agents with document understanding and context assembly.&#xA;📚 Table of Contents Overview Basic Configuration Advanced Configuration Configuration Examples Best Practices Performance Tuning Migration Guide Troubleshooting 🎯 Overview What is RAG? RAG (Retrieval-Augmented Generation) enhances LLM responses by:&#xA;Retrieving relevant information from knowledge bases and personal memory Augmenting prompts with contextual information Generating informed responses based on retrieved knowledge Providing source attribution for transparency AgentFlow RAG Features Hybrid Search: Combines semantic similarity and keyword matching Document Processing: Automatic chunking and metadata extraction Context Assembly: Intelligent context building with token management Session Memory: Isolated memory per user or conversation Multiple Providers: Support for various vector databases ⚙️ Basic Configuration Minimal RAG Setup [memory] enabled = true provider = &#34;memory&#34; dimensions = 1536 [memory.embedding] provider = &#34;openai&#34; model = &#34;text-embedding-3-small&#34; [memory.rag] enabled = true chunk_size = 1000 top_k = 5&#xD;Core Memory Settings [memory] enabled = true provider = &#34;pgvector&#34; # Options: memory, pgvector, weaviate connection = &#34;postgres://user:password@localhost:5432/agentflow&#34; max_results = 10 # Maximum personal memory results dimensions = 1536 # Vector embedding dimensions auto_embed = true # Automatically generate embeddings&#xD;RAG Configuration [memory.rag] enabled = true # Enable RAG functionality chunk_size = 1000 # Document chunk size in characters overlap = 200 # Overlap between chunks top_k = 5 # Number of results to retrieve score_threshold = 0.7 # Minimum similarity score hybrid_search = true # Enable hybrid search session_memory = true # Enable session isolation&#xD;🔧 Advanced Configuration Document Processing [memory.documents] auto_chunk = true # Automatically chunk documents supported_types = [&#34;pdf&#34;, &#34;txt&#34;, &#34;md&#34;, &#34;web&#34;, &#34;code&#34;, &#34;json&#34;] max_file_size = &#34;10MB&#34; # Maximum file size enable_metadata_extraction = true # Extract document metadata enable_url_scraping = true # Enable web content scraping&#xD;Embedding Configuration [memory.embedding] provider = &#34;openai&#34; # Options: openai, azure, ollama, dummy model = &#34;text-embedding-3-small&#34; # Embedding model api_key = &#34;${OPENAI_API_KEY}&#34; # API key (environment variable) base_url = &#34;&#34; # Custom endpoint (optional) max_batch_size = 50 # Batch size for embeddings timeout_seconds = 30 # Request timeout cache_embeddings = true # Cache embeddings for performance&#xD;Search Configuration [memory.search] hybrid_search = true # Enable hybrid search keyword_weight = 0.3 # Weight for keyword search (BM25) semantic_weight = 0.7 # Weight for semantic search enable_reranking = false # Enable result re-ranking reranking_model = &#34;&#34; # Re-ranking model (optional) enable_query_expansion = false # Enable query expansion&#xD;Context Assembly [memory.context] max_tokens = 4000 # Maximum context tokens personal_weight = 0.3 # Weight for personal memory knowledge_weight = 0.7 # Weight for knowledge base include_sources = true # Include source attribution include_history = true # Include chat history history_limit = 5 # Number of history messages&#xD;📋 Configuration Examples Development Configuration # agentflow.dev.toml - Development setup [memory] enabled = true provider = &#34;memory&#34; # In-memory for fast iteration max_results = 10 dimensions = 1536 auto_embed = true [memory.embedding] provider = &#34;dummy&#34; # Dummy embeddings for testing model = &#34;text-embedding-3-small&#34; cache_embeddings = true [memory.rag] enabled = true chunk_size = 800 # Smaller chunks for testing overlap = 150 top_k = 3 # Fewer results for faster testing score_threshold = 0.5 # Lower threshold for development hybrid_search = false # Disable for simplicity session_memory = false [memory.documents] auto_chunk = true supported_types = [&#34;txt&#34;, &#34;md&#34;, &#34;code&#34;] max_file_size = &#34;5MB&#34; enable_metadata_extraction = false # Disable for speed enable_url_scraping = false&#xD;Production Configuration # agentflow.prod.toml - Production deployment [memory] enabled = true provider = &#34;pgvector&#34; connection = &#34;postgres://user:password@localhost:5432/agentflow?sslmode=require&#34; max_results = 10 dimensions = 1536 auto_embed = true [memory.pgvector] table_name = &#34;agent_memory&#34; connection_pool_size = 25 [memory.embedding] provider = &#34;openai&#34; model = &#34;text-embedding-3-small&#34; api_key = &#34;${OPENAI_API_KEY}&#34; cache_embeddings = true max_batch_size = 100 timeout_seconds = 30 [memory.rag] enabled = true chunk_size = 1000 overlap = 200 top_k = 5 score_threshold = 0.7 hybrid_search = true session_memory = true [memory.documents] auto_chunk = true supported_types = [&#34;pdf&#34;, &#34;txt&#34;, &#34;md&#34;, &#34;web&#34;, &#34;code&#34;, &#34;json&#34;] max_file_size = &#34;10MB&#34; enable_metadata_extraction = true enable_url_scraping = true [memory.context] max_tokens = 4000 personal_weight = 0.3 knowledge_weight = 0.7 include_sources = true include_history = true history_limit = 5 [memory.search] hybrid_search = true keyword_weight = 0.3 semantic_weight = 0.7 enable_reranking = false enable_query_expansion = false [memory.advanced] retry_max_attempts = 3 retry_base_delay = &#34;100ms&#34; retry_max_delay = &#34;5s&#34; health_check_interval = &#34;1m&#34;&#xD;Enterprise Configuration # agentflow.enterprise.toml - Large-scale deployment [memory] enabled = true provider = &#34;weaviate&#34; connection = &#34;https://weaviate.company.com:8080&#34; max_results = 15 dimensions = 1536 auto_embed = true [memory.weaviate] api_key = &#34;${WEAVIATE_API_KEY}&#34; class_name = &#34;AgentMemory&#34; timeout = &#34;30s&#34; max_retries = 3 [memory.embedding] provider = &#34;azure&#34; model = &#34;text-embedding-ada-002&#34; api_key = &#34;${AZURE_OPENAI_API_KEY}&#34; endpoint = &#34;${AZURE_OPENAI_ENDPOINT}&#34; cache_embeddings = true max_batch_size = 100 timeout_seconds = 45 [memory.rag] enabled = true chunk_size = 1200 overlap = 240 top_k = 8 score_threshold = 0.75 hybrid_search = true session_memory = true [memory.context] max_tokens = 6000 # Larger context for enterprise personal_weight = 0.2 knowledge_weight = 0.8 # Knowledge-focused include_sources = true include_history = true history_limit = 10 [memory.search] hybrid_search = true keyword_weight = 0.25 semantic_weight = 0.75 enable_reranking = true reranking_model = &#34;cross-encoder/ms-marco-MiniLM-L-12-v2&#34; enable_query_expansion = true&#xD;🚀 Best Practices Provider Selection Use Case Recommended Provider Reason Development memory Fast iteration, no setup Production pgvector Reliable, performant, mature Enterprise weaviate Advanced features, clustering Prototyping memory Quick testing, temporary data Chunking Strategy # Document type specific chunking [memory.rag] # For technical documentation chunk_size = 1000 overlap = 200 # For code files chunk_size = 800 overlap = 100 # For research papers chunk_size = 1500 overlap = 300&#xD;Guidelines:</description>
    </item>
    <item>
      <title>ToolIntegration</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/toolintegration/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/toolintegration/index.html</guid>
      <description>Tool Integration Dynamic Tool Discovery and Execution with MCP Protocol&#xA;AgentFlow uses the Model Context Protocol (MCP) to provide agents with dynamic tool discovery and execution capabilities. This guide covers everything from basic tool usage to building custom MCP servers.&#xA;Overview The MCP integration in AgentFlow provides:&#xA;Dynamic Discovery: Tools are discovered at runtime, not hard-coded Schema-Based: Tools provide their own descriptions and parameters LLM-Driven: The LLM decides which tools to use based on context Extensible: Add new tools by connecting MCP servers Core MCP Functions AgentFlow provides two key functions that handle all MCP complexity:</description>
    </item>
    <item>
      <title>PgVectorSetup</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/pgvectorsetup/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/pgvectorsetup/index.html</guid>
      <description>PostgreSQL + pgvector Setup Guide Complete guide for setting up PostgreSQL with pgvector for AgentFlow memory&#xA;This guide provides detailed instructions for setting up PostgreSQL with the pgvector extension for production AgentFlow deployments.&#xA;🎯 Overview PostgreSQL with pgvector provides:&#xA;Persistent storage for agent memories and knowledge base Vector similarity search with excellent performance (~45ms queries) ACID transactions for data consistency Production-ready scalability and reliability Advanced indexing for optimal query performance 📋 Prerequisites Docker (recommended) OR PostgreSQL 12+ 2GB+ RAM available Network access to PostgreSQL port (5432) Basic command line knowledge 🚀 Quick Start (Docker) Step 1: Run PostgreSQL with pgvector # Create and start PostgreSQL container with pgvector docker run -d \ --name agentflow-postgres \ -e POSTGRES_DB=agentflow \ -e POSTGRES_USER=agentflow \ -e POSTGRES_PASSWORD=password \ -p 5432:5432 \ -v postgres_data:/var/lib/postgresql/data \ pgvector/pgvector:pg16 # Wait for container to start echo &#34;Waiting for PostgreSQL to start...&#34; sleep 10 # Verify container is running docker ps | grep agentflow-postgres&#xD;Step 2: Initialize Database # Connect to database and enable pgvector docker exec -it agentflow-postgres psql -U agentflow -d agentflow -c &#34; CREATE EXTENSION IF NOT EXISTS vector; SELECT extname, extversion FROM pg_extension WHERE extname = &#39;vector&#39;; &#34; # Expected output: vector | 0.5.1 (or similar)&#xD;Step 3: Test Connection # Test connection string docker exec -it agentflow-postgres psql -U agentflow -d agentflow -c &#34; SELECT version(); SELECT * FROM pg_extension WHERE extname = &#39;vector&#39;; &#34;&#xD;Step 4: Configure AgentFlow Create agentflow.toml:</description>
    </item>
    <item>
      <title>WeaviateSetup</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/weaviatesetup/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/weaviatesetup/index.html</guid>
      <description>Weaviate Setup Guide Complete guide for setting up Weaviate vector database for AgentFlow memory&#xA;This guide provides detailed instructions for setting up Weaviate as a vector database backend for AgentFlow’s memory system, from development to production deployment.&#xA;🎯 Overview Weaviate provides:&#xA;Purpose-built vector database optimized for similarity search GraphQL API for flexible queries and data management Built-in clustering for horizontal scalability Advanced search features including hybrid search and filtering Rich ecosystem with integrations and modules 📋 Prerequisites Docker (recommended) OR Kubernetes 4GB+ RAM available (8GB+ recommended for production) Network access to Weaviate port (8080) Basic command line knowledge 🚀 Quick Start (Docker) Step 1: Run Weaviate # Create and start Weaviate container docker run -d \ --name agentflow-weaviate \ -p 8080:8080 \ -e QUERY_DEFAULTS_LIMIT=25 \ -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=&#39;true&#39; \ -e PERSISTENCE_DATA_PATH=&#39;/var/lib/weaviate&#39; \ -e DEFAULT_VECTORIZER_MODULE=&#39;none&#39; \ -e CLUSTER_HOSTNAME=&#39;node1&#39; \ -e ENABLE_MODULES=&#39;text2vec-openai,text2vec-cohere,text2vec-huggingface,ref2vec-centroid,generative-openai,qna-openai&#39; \ -v weaviate_data:/var/lib/weaviate \ semitechnologies/weaviate:1.22.4 # Wait for startup echo &#34;Waiting for Weaviate to start...&#34; sleep 15 # Verify Weaviate is running curl http://localhost:8080/v1/.well-known/ready&#xD;Step 2: Test Connection # Check Weaviate status curl http://localhost:8080/v1/meta # Expected response: JSON with version and modules info&#xD;Step 3: Configure AgentFlow Create agentflow.toml:</description>
    </item>
    <item>
      <title>Performance</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/performance/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/performance/index.html</guid>
      <description>Performance Tuning Guide This guide covers optimization techniques, benchmarking, and performance best practices for AgentFlow applications. Learn how to build high-throughput, low-latency agent systems.&#xA;🎯 Performance Overview AgentFlow is designed for high performance with:&#xA;Go’s Concurrency: Native goroutines and channels for parallel processing Event-Driven Architecture: Non-blocking event processing Connection Pooling: Efficient resource utilization Streaming Support: Low-memory processing of large datasets Intelligent Caching: Reduced redundant computations 📊 Benchmarking Basics Built-in Benchmarking AgentFlow includes benchmarking tools for measuring performance:</description>
    </item>
    <item>
      <title>ErrorHandling</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/errorhandling/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/errorhandling/index.html</guid>
      <description>Error Handling Guide AgentFlow provides comprehensive error handling mechanisms to build resilient agent systems. This guide covers error patterns, recovery strategies, and best practices for production-ready error handling.&#xA;🎯 Error Handling Philosophy AgentFlow follows these principles for error handling:&#xA;Graceful Degradation: Agents should continue functioning with reduced capabilities when possible Context Preservation: Error information should include enough context for debugging Recovery Strategies: Automatic retry and fallback mechanisms for transient failures User-Friendly Messages: End users should receive helpful, non-technical error messages 🔧 Core Error Types Agent Execution Errors Errors that occur during agent processing:</description>
    </item>
    <item>
      <title>deployment</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/deployment/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/deployment/index.html</guid>
      <description>Deployment &amp; Operations Guides Guides for deploying and operating AgenticGoKit applications in production.&#xA;Available Guides Docker Deployment Containerize your AgenticGoKit applications with Docker, including multi-stage builds and optimization techniques.&#xA;When to use: Deploying agents in containerized environments or cloud platforms.&#xA;Monitoring Set up comprehensive monitoring for agent performance, including metrics, logging, and alerting.&#xA;When to use: Running agents in production and need visibility into system health and performance.&#xA;Scaling Scale AgenticGoKit applications horizontally, including load balancing and distributed deployment patterns.</description>
    </item>
    <item>
      <title>development</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/development/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/development/index.html</guid>
      <description>Development Guides Guides for developing, testing, and debugging AgenticGoKit applications.&#xA;Available Guides Testing Agents Comprehensive guide to testing multi-agent systems, including unit tests, integration tests, and end-to-end testing strategies.&#xA;When to use: Building reliable agent systems that need thorough testing coverage.&#xA;Debugging Debug agent interactions, trace execution flows, and troubleshoot common issues in multi-agent systems.&#xA;When to use: When agents aren’t behaving as expected or you need to understand execution flow.</description>
    </item>
    <item>
      <title>framework-comparison</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/framework-comparison/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/framework-comparison/index.html</guid>
      <description>Framework Comparison: AgenticGoKit vs. Alternatives Straightforward feature-driven comparison of leading agent frameworks for building multi-agent systems.&#xA;Note: AgenticGoKit is Go-based and in preview; Comparison reflects capabilities as of July 2025.&#xA;📊 Feature Set Comparison Feature AgenticGoKit LangChain AutoGen CrewAI Semantic Kernel Agno Language Go Python Python Python C#/Python Python Maturity Preview Stable Stable Growing Stable Early‑stage, but active Community Size ⭐ ⭐⭐⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐⭐ Multi-Agent Focus ⭐⭐⭐⭐ ⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐ ⭐⭐⭐⭐ Memory Systems ⭐⭐⭐⭐ ⭐⭐⭐⭐⭐ ⭐⭐ ⭐⭐⭐ ⭐⭐⭐ ⭐⭐⭐⭐ Tool Integration ⭐⭐⭐⭐ ⭐⭐⭐⭐⭐ ⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐⭐ Documentation ⭐⭐⭐ ⭐⭐⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐ ⭐⭐⭐⭐ ⭐⭐⭐ Performance High Moderate Moderate Moderate Moderate High Monitoring Developing Manual Limited Basic Azure-native Built-in Modularity ✅ ✅ ✅ ✅ ✅ ✅ 🚀 AgenticGoKit: The Go-Native Approach Why Go for Agent Systems? // AgenticGoKit: Leverages Go&#39;s concurrency model func (r *Runner) ProcessEvents(ctx context.Context, events []core.Event) { var wg sync.WaitGroup results := make(chan *core.AgentResult, len(events)) for _, event := range events { wg.Add(1) go func(e core.Event) { defer wg.Done() result, _ := r.processEvent(ctx, e) results &lt;- result }(event) } wg.Wait() close(results) }&#xD;Go Language Benefits:</description>
    </item>
    <item>
      <title>Memory</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/memory/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/memory/index.html</guid>
      <description>AgenticGoKit Memory System - Complete Implementation Guide 🎯 Overview AgenticGoKit provides a powerful, production-ready memory system that enables agents to maintain persistent context, conversation history, and knowledge bases. The system supports multiple storage backends, RAG (Retrieval-Augmented Generation) capabilities, and advanced features like vector embeddings, batch operations, and intelligent retry logic.&#xA;📚 Table of Contents Quick Start Core Concepts Configuration Memory Providers API Reference RAG (Retrieval-Augmented Generation) Advanced Features Examples Performance &amp; Optimization Troubleshooting 🚀 Quick Start 1. Basic Setup package main import ( &#34;context&#34; &#34;log&#34; &#34;github.com/kunalkushwaha/agenticgokit/core&#34; ) func main() { // Create memory configuration config := core.AgentMemoryConfig{ Provider: &#34;memory&#34;, // In-memory for development Connection: &#34;memory&#34;, Dimensions: 1536, Embedding: core.EmbeddingConfig{ Provider: &#34;dummy&#34;, // For testing Model: &#34;text-embedding-3-small&#34;, }, } // Create memory provider memory, err := core.NewMemory(config) if err != nil { log.Fatal(err) } defer memory.Close() // Create context with session ctx := memory.SetSession(context.Background(), &#34;user-123&#34;) // Store a memory err = memory.Store(ctx, &#34;I love programming in Go&#34;, &#34;programming&#34;, &#34;preference&#34;) if err != nil { log.Fatal(err) } // Query memories results, err := memory.Query(ctx, &#34;programming languages&#34;, 5) if err != nil { log.Fatal(err) } for _, result := range results { fmt.Printf(&#34;Content: %s, Score: %.2f\n&#34;, result.Content, result.Score) } }&#xD;2. Configuration File Setup Create an agentflow.toml configuration file:</description>
    </item>
    <item>
      <title>ScaffoldMemoryGuide</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/scaffoldmemoryguide/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/scaffoldmemoryguide/index.html</guid>
      <description>Scaffold Memory System Guide This guide explains how to use AgentFlow’s enhanced scaffold system to create projects with intelligent memory configuration. The scaffold now includes automatic embedding model intelligence, configuration validation, and comprehensive troubleshooting support.&#xA;Quick Start Basic Memory-Enabled Project # Create a project with intelligent defaults agentcli create myproject --memory-enabled # The system automatically: # - Selects nomic-embed-text:latest (768 dimensions) # - Configures pgvector as memory provider # - Sets up RAG with optimal parameters # - Generates validation and troubleshooting code&#xD;Production-Ready Setup # Create a production-ready project agentcli create myapp --memory-enabled \ --memory-provider pgvector \ --embedding-provider ollama \ --embedding-model nomic-embed-text:latest \ --rag-enabled \ --hybrid-search \ --session-memory&#xD;Embedding Model Intelligence The scaffold system now includes intelligent embedding model configuration:</description>
    </item>
    <item>
      <title>setup</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/setup/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/setup/index.html</guid>
      <description>Setup &amp; Configuration Guides Guides for setting up and configuring AgenticGoKit components.&#xA;Available Guides LLM Providers Configure different Large Language Model providers including OpenAI, Anthropic, and local models.&#xA;When to use: Setting up your first agent or switching LLM providers.&#xA;Vector Databases Set up vector storage systems for Retrieval-Augmented Generation (RAG) including pgvector and Weaviate.&#xA;When to use: Building agents that need to search through documents or knowledge bases.&#xA;MCP Tools Integrate Model Context Protocol tools to extend agent capabilities with external services.</description>
    </item>
    <item>
      <title>troubleshooting</title>
      <link>http://localhost:1313/AgenticGoKitDocs/guides/troubleshooting/index.html</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/AgenticGoKitDocs/guides/troubleshooting/index.html</guid>
      <description>Troubleshooting Guide Quick solutions for common AgenticGoKit issues&#xA;This guide helps you diagnose and resolve common problems when building with AgenticGoKit. Issues are organized by category with step-by-step solutions and prevention tips.&#xA;🚨 Quick Diagnostics Health Check Commands # Check AgenticGoKit installation agentcli version # Verify project structure agentcli validate # Test basic functionality go run . -m &#34;Hello, world!&#34; --dry-run&#xD;Common Error Patterns Error Pattern Likely Cause Quick Fix connection refused Service not running Start required services API key not found Missing environment variables Set API keys agent not found Registration issue Check agent registration timeout Performance or network issue Increase timeouts out of memory Resource exhaustion Optimize memory usage 🔧 Installation &amp; Setup Issues AgenticGoKit CLI Not Found Symptoms:</description>
    </item>
  </channel>
</rss>